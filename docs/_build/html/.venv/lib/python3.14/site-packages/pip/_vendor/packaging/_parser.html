

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>————————————————————————————– &mdash; Retrogue 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../_static/custom.css?v=a6a68382" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../_static/fonts.css?v=5583d106" />

  
      <script src="../../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../../_static/documentation_options.js?v=d45e8c67"></script>
      <script src="../../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../../index.html" class="icon icon-home">
            Retrogue
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../modules.html">src</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../index.html">Retrogue</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">————————————————————————————–</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../_sources/.venv/lib/python3.14/site-packages/pip/_vendor/packaging/_parser.py.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>“””Handwritten parser of dependency specifiers.</p>
<p>The docstring for each _<em>parse</em>* function contains EBNF-inspired grammar representing
the implementation.
“””</p>
<p>from <strong>future</strong> import annotations</p>
<p>import ast
from typing import NamedTuple, Sequence, Tuple, Union</p>
<p>from ._tokenizer import DEFAULT_RULES, Tokenizer</p>
<p>class Node:
def <strong>init</strong>(self, value: str) -&gt; None:
self.value = value</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>def __str__(self) -&gt; str:
    return self.value

def __repr__(self) -&gt; str:
    return f&quot;&lt;{self.__class__.__name__}(&#39;{self}&#39;)&gt;&quot;

def serialize(self) -&gt; str:
    raise NotImplementedError
</pre></div>
</div>
<p>class Variable(Node):
def serialize(self) -&gt; str:
return str(self)</p>
<p>class Value(Node):
def serialize(self) -&gt; str:
return f’”{self}”’</p>
<p>class Op(Node):
def serialize(self) -&gt; str:
return str(self)</p>
<p>MarkerVar = Union[Variable, Value]
MarkerItem = Tuple[MarkerVar, Op, MarkerVar]
MarkerAtom = Union[MarkerItem, Sequence[“MarkerAtom”]]
MarkerList = Sequence[Union[“MarkerList”, MarkerAtom, str]]</p>
<p>class ParsedRequirement(NamedTuple):
name: str
url: str
extras: list[str]
specifier: str
marker: MarkerList | None</p>
<section id="id1">
<h1>————————————————————————————–<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
</section>
<section id="recursive-descent-parser-for-dependency-specifier">
<h1>Recursive descent parser for dependency specifier<a class="headerlink" href="#recursive-descent-parser-for-dependency-specifier" title="Link to this heading"></a></h1>
</section>
<section id="id2">
<h1>————————————————————————————–<a class="headerlink" href="#id2" title="Link to this heading"></a></h1>
<p>def parse_requirement(source: str) -&gt; ParsedRequirement:
return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))</p>
<p>def _parse_requirement(tokenizer: Tokenizer) -&gt; ParsedRequirement:
“””
requirement = WS? IDENTIFIER WS? extras WS? requirement_details
“””
tokenizer.consume(“WS”)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>name_token = tokenizer.expect(
    &quot;IDENTIFIER&quot;, expected=&quot;package name at the start of dependency specifier&quot;
)
name = name_token.text
tokenizer.consume(&quot;WS&quot;)

extras = _parse_extras(tokenizer)
tokenizer.consume(&quot;WS&quot;)

url, specifier, marker = _parse_requirement_details(tokenizer)
tokenizer.expect(&quot;END&quot;, expected=&quot;end of dependency specifier&quot;)

return ParsedRequirement(name, url, extras, specifier, marker)
</pre></div>
</div>
<p>def _parse_requirement_details(
tokenizer: Tokenizer,
) -&gt; tuple[str, str, MarkerList | None]:
“””
requirement_details = AT URL (WS requirement_marker?)?
| specifier WS? (requirement_marker)?
“””</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>specifier = &quot;&quot;
url = &quot;&quot;
marker = None

if tokenizer.check(&quot;AT&quot;):
    tokenizer.read()
    tokenizer.consume(&quot;WS&quot;)

    url_start = tokenizer.position
    url = tokenizer.expect(&quot;URL&quot;, expected=&quot;URL after @&quot;).text
    if tokenizer.check(&quot;END&quot;, peek=True):
        return (url, specifier, marker)

    tokenizer.expect(&quot;WS&quot;, expected=&quot;whitespace after URL&quot;)

    # The input might end after whitespace.
    if tokenizer.check(&quot;END&quot;, peek=True):
        return (url, specifier, marker)

    marker = _parse_requirement_marker(
        tokenizer, span_start=url_start, after=&quot;URL and whitespace&quot;
    )
else:
    specifier_start = tokenizer.position
    specifier = _parse_specifier(tokenizer)
    tokenizer.consume(&quot;WS&quot;)

    if tokenizer.check(&quot;END&quot;, peek=True):
        return (url, specifier, marker)

    marker = _parse_requirement_marker(
        tokenizer,
        span_start=specifier_start,
        after=(
            &quot;version specifier&quot;
            if specifier
            else &quot;name and no valid version specifier&quot;
        ),
    )

return (url, specifier, marker)
</pre></div>
</div>
<p>def _parse_requirement_marker(
tokenizer: Tokenizer, *, span_start: int, after: str
) -&gt; MarkerList:
“””
requirement_marker = SEMICOLON marker WS?
“””</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>if not tokenizer.check(&quot;SEMICOLON&quot;):
    tokenizer.raise_syntax_error(
        f&quot;Expected end or semicolon (after {after})&quot;,
        span_start=span_start,
    )
tokenizer.read()

marker = _parse_marker(tokenizer)
tokenizer.consume(&quot;WS&quot;)

return marker
</pre></div>
</div>
<p>def _parse_extras(tokenizer: Tokenizer) -&gt; list[str]:
“””
extras = (LEFT_BRACKET wsp* extras_list? wsp* RIGHT_BRACKET)?
“””
if not tokenizer.check(“LEFT_BRACKET”, peek=True):
return []</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>with tokenizer.enclosing_tokens(
    &quot;LEFT_BRACKET&quot;,
    &quot;RIGHT_BRACKET&quot;,
    around=&quot;extras&quot;,
):
    tokenizer.consume(&quot;WS&quot;)
    extras = _parse_extras_list(tokenizer)
    tokenizer.consume(&quot;WS&quot;)

return extras
</pre></div>
</div>
<p>def _parse_extras_list(tokenizer: Tokenizer) -&gt; list[str]:
“””
extras_list = identifier (wsp* ‘,’ wsp* identifier)*
“””
extras: list[str] = []</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>if not tokenizer.check(&quot;IDENTIFIER&quot;):
    return extras

extras.append(tokenizer.read().text)

while True:
    tokenizer.consume(&quot;WS&quot;)
    if tokenizer.check(&quot;IDENTIFIER&quot;, peek=True):
        tokenizer.raise_syntax_error(&quot;Expected comma between extra names&quot;)
    elif not tokenizer.check(&quot;COMMA&quot;):
        break

    tokenizer.read()
    tokenizer.consume(&quot;WS&quot;)

    extra_token = tokenizer.expect(&quot;IDENTIFIER&quot;, expected=&quot;extra name after comma&quot;)
    extras.append(extra_token.text)

return extras
</pre></div>
</div>
<p>def _parse_specifier(tokenizer: Tokenizer) -&gt; str:
“””
specifier = LEFT_PARENTHESIS WS? version_many WS? RIGHT_PARENTHESIS
| WS? version_many WS?
“””
with tokenizer.enclosing_tokens(
“LEFT_PARENTHESIS”,
“RIGHT_PARENTHESIS”,
around=”version specifier”,
):
tokenizer.consume(“WS”)
parsed_specifiers = _parse_version_many(tokenizer)
tokenizer.consume(“WS”)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>return parsed_specifiers
</pre></div>
</div>
<p>def _parse_version_many(tokenizer: Tokenizer) -&gt; str:
“””
version_many = (SPECIFIER (WS? COMMA WS? SPECIFIER)<em>)?
“””
parsed_specifiers = “”
while tokenizer.check(“SPECIFIER”):
span_start = tokenizer.position
parsed_specifiers += tokenizer.read().text
if tokenizer.check(“VERSION_PREFIX_TRAIL”, peek=True):
tokenizer.raise_syntax_error(
“.</em> suffix can only be used with <code class="docutils literal notranslate"><span class="pre">==</span></code> or <code class="docutils literal notranslate"><span class="pre">!=</span></code> operators”,
span_start=span_start,
span_end=tokenizer.position + 1,
)
if tokenizer.check(“VERSION_LOCAL_LABEL_TRAIL”, peek=True):
tokenizer.raise_syntax_error(
“Local version label can only be used with <code class="docutils literal notranslate"><span class="pre">==</span></code> or <code class="docutils literal notranslate"><span class="pre">!=</span></code> operators”,
span_start=span_start,
span_end=tokenizer.position,
)
tokenizer.consume(“WS”)
if not tokenizer.check(“COMMA”):
break
parsed_specifiers += tokenizer.read().text
tokenizer.consume(“WS”)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>return parsed_specifiers
</pre></div>
</div>
</section>
<section id="id3">
<h1>————————————————————————————–<a class="headerlink" href="#id3" title="Link to this heading"></a></h1>
</section>
<section id="recursive-descent-parser-for-marker-expression">
<h1>Recursive descent parser for marker expression<a class="headerlink" href="#recursive-descent-parser-for-marker-expression" title="Link to this heading"></a></h1>
</section>
<section id="id4">
<h1>————————————————————————————–<a class="headerlink" href="#id4" title="Link to this heading"></a></h1>
<p>def parse_marker(source: str) -&gt; MarkerList:
return _parse_full_marker(Tokenizer(source, rules=DEFAULT_RULES))</p>
<p>def _parse_full_marker(tokenizer: Tokenizer) -&gt; MarkerList:
retval = _parse_marker(tokenizer)
tokenizer.expect(“END”, expected=”end of marker expression”)
return retval</p>
<p>def _parse_marker(tokenizer: Tokenizer) -&gt; MarkerList:
“””
marker = marker_atom (BOOLOP marker_atom)+
“””
expression = [_parse_marker_atom(tokenizer)]
while tokenizer.check(“BOOLOP”):
token = tokenizer.read()
expr_right = _parse_marker_atom(tokenizer)
expression.extend((token.text, expr_right))
return expression</p>
<p>def _parse_marker_atom(tokenizer: Tokenizer) -&gt; MarkerAtom:
“””
marker_atom = WS? LEFT_PARENTHESIS WS? marker WS? RIGHT_PARENTHESIS WS?
| WS? marker_item WS?
“””</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tokenizer.consume(&quot;WS&quot;)
if tokenizer.check(&quot;LEFT_PARENTHESIS&quot;, peek=True):
    with tokenizer.enclosing_tokens(
        &quot;LEFT_PARENTHESIS&quot;,
        &quot;RIGHT_PARENTHESIS&quot;,
        around=&quot;marker expression&quot;,
    ):
        tokenizer.consume(&quot;WS&quot;)
        marker: MarkerAtom = _parse_marker(tokenizer)
        tokenizer.consume(&quot;WS&quot;)
else:
    marker = _parse_marker_item(tokenizer)
tokenizer.consume(&quot;WS&quot;)
return marker
</pre></div>
</div>
<p>def _parse_marker_item(tokenizer: Tokenizer) -&gt; MarkerItem:
“””
marker_item = WS? marker_var WS? marker_op WS? marker_var WS?
“””
tokenizer.consume(“WS”)
marker_var_left = _parse_marker_var(tokenizer)
tokenizer.consume(“WS”)
marker_op = _parse_marker_op(tokenizer)
tokenizer.consume(“WS”)
marker_var_right = _parse_marker_var(tokenizer)
tokenizer.consume(“WS”)
return (marker_var_left, marker_op, marker_var_right)</p>
<p>def <em>parse_marker_var(tokenizer: Tokenizer) -&gt; MarkerVar:
“””
marker_var = VARIABLE | QUOTED_STRING
“””
if tokenizer.check(“VARIABLE”):
return process_env_var(tokenizer.read().text.replace(“.”, “</em>”))
elif tokenizer.check(“QUOTED_STRING”):
return process_python_str(tokenizer.read().text)
else:
tokenizer.raise_syntax_error(
message=”Expected a marker variable or quoted string”
)</p>
<p>def process_env_var(env_var: str) -&gt; Variable:
if env_var in (“platform_python_implementation”, “python_implementation”):
return Variable(“platform_python_implementation”)
else:
return Variable(env_var)</p>
<p>def process_python_str(python_str: str) -&gt; Value:
value = ast.literal_eval(python_str)
return Value(str(value))</p>
<p>def _parse_marker_op(tokenizer: Tokenizer) -&gt; Op:
“””
marker_op = IN | NOT IN | OP
“””
if tokenizer.check(“IN”):
tokenizer.read()
return Op(“in”)
elif tokenizer.check(“NOT”):
tokenizer.read()
tokenizer.expect(“WS”, expected=”whitespace after ‘not’”)
tokenizer.expect(“IN”, expected=“‘in’ after ‘not’”)
return Op(“not in”)
elif tokenizer.check(“OP”):
return Op(tokenizer.read().text)
else:
return tokenizer.raise_syntax_error(
“Expected marker operator, one of &lt;=, &lt;, !=, ==, &gt;=, &gt;, ~=, ===, in, not in”
)</p>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Adam Worsnip.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>